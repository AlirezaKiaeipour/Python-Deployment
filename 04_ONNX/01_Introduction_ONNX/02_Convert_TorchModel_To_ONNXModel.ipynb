{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5p2Y2Cyc1Mr"
   },
   "outputs": [],
   "source": [
    "!pip install onnx\n",
    "!pip install onnxscript\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QBtVUGKgdHel"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mFHeG8HxeE9W"
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "torch_model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Torch Model To ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jteUqHmPeffA",
    "outputId": "6df209b3-3807-4516-cbd5-b2d121043758"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch_input = torch.randn(1, 1, 32, 32)\n",
    "onnx_model = torch.onnx.dynamo_export(torch_model, torch_input)\n",
    "onnx_model.save(\"pytorch_to_onnx_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q6-zavteeg-I"
   },
   "outputs": [],
   "source": [
    "onnx_model_check = onnx.load_model(\"/content/pytorch_to_onnx_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LefpfEjCYkR",
    "outputId": "37fd9956-65d9-4f26-e477-4fd9679d22c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_x_ fc3_1\n"
     ]
    }
   ],
   "source": [
    "onnx_model_session = ort.InferenceSession(\n",
    "    \"/content/pytorch_to_onnx_model.onnx\",\n",
    "    providers = [\"CPUExecutionProvider\"]\n",
    ")\n",
    "input_name = onnx_model_session.get_inputs()[0].name\n",
    "output_name = onnx_model_session.get_outputs()[0].name\n",
    "print(input_name, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n88t4JotD4yl",
    "outputId": "16f7ed9c-fe84-4500-eef9-62a7ab66ca20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03642596,  0.09679464, -0.10962822,  0.05402166, -0.13292298,\n",
       "          0.03535164, -0.06996707, -0.02941129, -0.07467412,  0.0602996 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch_input.detach().cpu().numpy()\n",
    "predict = onnx_model_session.run(\n",
    "    [output_name],\n",
    "    {input_name:input_data}\n",
    ")\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare The PyTorch Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjtrnY8EEpqY",
    "outputId": "ecf4b184-06c0-4e1b-a754-9bf146bc7e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch and ONNX Runtime output matched!\n",
      "Output length: 1\n",
      "Sample output: [array([[-0.03642596,  0.09679464, -0.10962822,  0.05402166, -0.13292298,\n",
      "         0.03535164, -0.06996707, -0.02941129, -0.07467412,  0.0602996 ]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "torch_outputs = torch_model(torch_input)\n",
    "torch_outputs = onnx_model.adapt_torch_outputs_to_onnx(torch_outputs)\n",
    "\n",
    "assert len(torch_outputs) == len(predict)\n",
    "for torch_output, onnxruntime_output in zip(torch_outputs, predict):\n",
    "    torch.testing.assert_close(torch_output, torch.tensor(onnxruntime_output))\n",
    "\n",
    "print(\"PyTorch and ONNX Runtime output matched!\")\n",
    "print(f\"Output length: {len(predict)}\")\n",
    "print(f\"Sample output: {predict}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
